export interface BlogPost {
  image: string; // thumbnail image path
  model?: string; // optional GLB model path for 3D
  position?: [number, number, number]; // optional [x, y, z] position for 3D scene
  rotationDeg?: [number, number, number]; // optional [x, y, z] rotation in degrees for 3D scene
  authorName?: string;
  authorImage?: string;
  id: string;
  title: string;
  subtitle?: string;
  published: string;
  content: string[];
}

export const qualityPhilosophyPosts: BlogPost[] = [
  {
    id: "dynamic-test-data",
    title: "Automation should validate intent, while allowing reality to vary.",
    subtitle: "Getting More Value from Test Automation",
    published: "2026-01-08",
    content: [
      "## Context",
      "Test automation is a powerful tool for enabling fast feedback — I love that about it.",
      "However, many teams struggle to get full value out of automation because their tests run with overly static inputs.",
      "",
      "## The problem with purely static data",
      "Most automated tests validate a specific intent (a function or feature) and therefore need some controlled inputs.",
      "The mistake is treating every input as equally static, even when some values could safely vary without changing the intent being validated.",
      "",
      "## A dynamic test data approach",
      "Keep critical inputs stable, but allow non-critical inputs to vary dynamically.",
      "",
      "By doing this, you can:",
      "- Increase coverage",
      "- Explore edge cases naturally",
      "- Surface defects that static data would never expose",
      "",
      "All without compromising the intent of the test.",
      "",
      "## A practical example (login)",
      "To validate authentication:",
      "- Username and password must be correct and controlled",
      "",
      "But these can vary without invalidating the intent:",
      "- Browser type",
      "- Screen resolution",
      "",
      "## Closing Thought",
      "Dynamic data doesn’t mean unreliable tests.",
      "It means stable intent with realistic variation — and stronger confidence over time. This approach can be paired with the Telemetry Informed Regresson Test Plan Apprach which you can read about here (/quality/telemetry-tests-release-quality-cycle)"
    ],
    image: '/images/splashing-water.jpeg',
    model: '/images/dynamic_quality_system.glb',
    authorName: 'Sandile Mnqayi',
    authorImage: '/images/SandileMnqayi.jpeg'
  },
  {
    id: "deadlines-enemy-of-quality",
    title: "When Deadlines Become the Enemy of Quality",
    subtitle: "How deadline-driven incentives quietly train teams to ship risk",
    rotationDeg: [120, 10, 125],
    published: "2026-01-10",
    content: [
      "In many organisations, delivery success is measured by one dominant signal: did we hit the deadline?",
      "Deadlines are usually tied to KPIs, performance reviews, bonuses, and leadership visibility.",
      "On paper, this makes sense — timelines bring structure and predictability.",
      "In practice, however, this incentive model often produces the opposite of what teams intend: lower quality outcomes.",
      "",
      "When meeting a deadline becomes the primary goal, quality quietly becomes optional.",
      "",
      "## The KPI Trap: Speed Over Substance",
      "KPIs are powerful because they shape behaviour.",
      "When teams are rewarded for how fast something is delivered, they naturally optimise for speed.",
      "This leads to:",
      "",
      "- Cutting corners in design and implementation",
      "- Reduced testing depth",
      "- Shortened feedback cycles",
      "- Increased reliance on assumptions rather than evidence",
      "",
      "The problem is not that teams are careless.",
      "The problem is that they are responding rationally to the incentives placed in front of them.",
      "",
      "If quality is not explicitly measured, protected, and rewarded, it will always lose to time pressure.",
      "",
      "## “Just Make the Deadline” Culture",
      "As deadlines approach, pressure tends to cascade downward:",
      "",
      "- Senior leadership pushes product owners",
      "- Product owners push delivery teams",
      "- Delivery teams push QA",
      "",
      "At this stage, conversations shift from “Is this ready?” to “Can we sign this off?”",
      "Quality assurance becomes a gate that must be bypassed rather than a signal to be respected.",
      "",
      "This is where the most damaging behaviour emerges:",
      "QA teams are pressured to approve releases they are not confident in.",
      "",
      "## The Erosion of QA Authority",
      "When deadlines dominate decision-making:",
      "",
      "- QA findings are reframed as “non-blockers”",
      "- Known risks are deferred to “post-release”",
      "- Test coverage is treated as negotiable",
      "- Sign-off becomes ceremonial rather than meaningful",
      "",
      "Over time, this erodes trust in QA as a discipline.",
      "QA stops being a partner in risk management and becomes a formality in the delivery checklist.",
      "",
      "Ironically, the same stakeholders who push for rushed sign-off are often the first to question quality when defects surface in production.",
      "",
      "## The Hidden Cost of Rushed Delivery",
      "What deadline-driven KPIs fail to account for is cost displacement.",
      "",
      "Quality issues do not disappear when they are ignored — they simply move downstream:",
      "",
      "- Production defects",
      "- Customer dissatisfaction",
      "- Emergency hotfixes",
      "- Reputational damage",
      "- Burnout within engineering and QA teams",
      "",
      "The time “saved” before release is often paid back with interest after release.",
      "",
      "## Quality Needs an Incentive Too",
      "The core issue is not deadlines. Deadlines are necessary.",
      "The issue is unbalanced incentives.",
      "",
      "If teams are measured only on when something is delivered, but not on how well it performs, then quality becomes a risk the system is willing to take.",
      "",
      "Healthy delivery organisations balance:",
      "",
      "- Time",
      "- Scope",
      "- Risk",
      "- Quality",
      "",
      "And they give QA the authority to say “not yet” without fear of escalation or blame.",
      "",
      "## A Better Question to Ask",
      "Instead of asking:",
      "",
      "“Can we still make the deadline?”",
      "",
      "Teams should be encouraged to ask:",
      "",
      "“What level of quality are we willing to accept — and are we aligned on that risk?”",
      "",
      "That single shift reframes QA from an obstacle into a strategic partner.",
      "",
      "## Closing Thoughts",
      "When KPIs reward speed alone, they silently train teams to sacrifice quality.",
      "When QA is pressured to sign off against their judgement, quality becomes performative rather than real.",
      "",
      "True delivery maturity is not about hitting every deadline.",
      "It is about delivering outcomes that teams can confidently stand behind — even when that means pushing back.",
      "",
      "Quality does not happen by accident.",
      "It happens when organisations choose to incentivise it."
    ],
    image: '/images/deadlines.webp',
    model: '/images/flag-finish-model.glb',
    authorName: 'Sandile Mnqayi',
    authorImage: '/images/SandileMnqayi.jpeg'
  },
  {
    id: "telemetry-tests-release-quality-cycle",
    title: "From Telemetry to Tests to Release: A User-Behaviour-Driven Quality Cycle",
    rotationDeg: [90, 90, 130],
    published: "2026-01-10",
    content: [
      "One of the biggest gaps in modern software delivery is that testing is often disconnected from reality. Test scenarios are designed based on assumptions, specifications, and edge cases imagined during development, while production quietly tells a different story.",
      "",
      "The question is not how much we test, but how relevant our tests are to real user behaviour.",
      "",
      "By combining telemetry, AI, and test automation, teams can create a closed quality loop where production reality continuously informs what gets tested next.",
      "",
      "## The Core Cycle",
      "The cycle looks like this:",
      "",
      "- Telemetry captures real user behaviour",
      "- AI analyses telemetry and detects patterns",
      "- AI derives test scenarios and realistic input data",
      "- Test automation executes optimized tests in the test environment",
      "- A new release is shaped by these informed tests",
      "- The released system generates new telemetry",
      "- The cycle repeats, continuously improving coverage in key areas.",
      "",
      "The key shift is this:",
      "Test automation runs in the testbed, but learning happens in production.",
      "",
      "## 1. Telemetry as the partner Source of Truth",
      "Production telemetry represents how users actually interact with the system:",
      "",
      "- Navigation paths",
      "- Feature usage frequency",
      "- Real input values",
      "- Error patterns",
      "- Performance bottlenecks",
      "- Drop-offs and retries",
      "",
      "This data exposes the gap between:",
      "",
      "- What we thought users would do",
      "- What they actually do",
      "",
      "Telemetry is not feedback on tests — it is feedback on the product itself. This is BDD personified.",
      "",
      "## 2. AI Interprets Behaviour, Not Intent",
      "Raw telemetry is noisy and overwhelming. AI’s role is to interpret behaviour at scale.",
      "",
      "AI analyses telemetry to:",
      "",
      "- Identify dominant and rare user flows",
      "- Detect anomalies and emerging risk patterns",
      "- Correlate failures with inputs and paths",
      "- Highlight areas with high usage but low test coverage",
      "",
      "Instead of guessing what matters, teams get an evidence-based view of where risk actually lives.",
      "",
      "## 3. AI Derives Test Scenarios and Input Data",
      "This is the most important shift in the model.",
      "",
      "From analysed telemetry, AI can:",
      "",
      "- Identify gaps in the test suite and",
      "- Propose new test scenarios based on real flows",
      "- Generate realistic input data seen in production",
      "- Elevate rare but high-impact edge cases",
      "- De-prioritise low-value, synthetic tests. (//An under estimated cost is the time waisted fixing non-realistic edge cases.)",
      "",
      "Regression tests are no longer speculative, with telemetry informed AI powered test scenarios, they are user-behaviour-driven.",
      "",
      "",
      "This results in:",
      "",
      "- Fewer tests",
      "- Higher relevance",
      "- Better signal-to-noise ratio",
      "",
      "## 4. Test Automation Runs in the Testbed",
      "All execution happens in controlled test environments, not production.",
      "",
      "Test automation:",
      "",
      "- Validates fixes and changes informed by telemetry",
      "- Protects critical user journeys",
      "- Enforces contracts and non-regression",
      "- Surfaces risk before release, not after",
      "",
      "Automation enforces what we have learned.",
      "",
      "## 5. The Release Is the Feedback Mechanism",
      "This is the correction that makes the model sound.",
      "",
      "The output of test automation is:",
      "",
      "- A release with fixes",
      "- Adjusted behaviour",
      "- Reduced known risk",
      "",
      "Only after release does feedback return to telemetry.",
      "",
      "Production usage of the new release generates:",
      "",
      "- New behaviour patterns",
      "- New edge cases",
      "- New performance characteristics",
      "",
      "That telemetry becomes the next input into the cycle.",
      "",
      "## 6. A Living Quality System",
      "Over time, this creates a self-reinforcing system:",
      "",
      "- Telemetry informs what to test",
      "- Tests shape what is released",
      "- Releases create new telemetry",
      "- Coverage evolves with real usage",
      "",
      "Quality stops being a static checklist and becomes adaptive.",
      "",
      "## Why This Model Matters",
      "This approach solves several systemic problems:",
      "",
      "- Tests stay aligned with real users",
      "- QA is no longer the last-minute gatekeeper",
      "- Risk is identified early, not at deadlines",
      "- Acurate preventative test inteventions are implemented",
      "- Coverage grows where it matters, not where it is easiest",
      "",
      "Most importantly, it shifts the conversation from:",
      "",
      "“Did we test enough?”",
      "",
      "to:",
      "",
      "“Did we test what real users will actually do next?”",
      "",
      "## Closing Thought",
      "Telemetry tells us how the product is used.",
      "AI tells us where risk and opportunity exist.",
      "Test automation ensures those insights are enforced before release.",
      "",
      "The release itself becomes the experiment — and telemetry becomes the verdict.",
      "",
      "This is not faster testing.",
      "Thit is quality engineering driven by reality."
    ],
    image: '/images/telemetry-signals.jpeg',
    model: '/images/binocurlars.glb',
    authorName: 'Sandile Mnqayi',
    authorImage: '/images/SandileMnqayi.jpeg'
  },
  {
    id: "pitch-to-product-football-qa",
    title: "From Pitch to Product: Mapping Football Greats' Strengths to Software Testing Quality",
    published: "2026-01-10",
    content: [
      "## Introduction",
      "",
      "### Hook",
      "Football and software testing might seem worlds apart, but both thrive on discipline, adaptability, and excellence under pressure. Just as legendary footballers read the game, adjust their play, and relentlessly pursue victory, great QA engineers navigate complex systems, shifting requirements, and ever-rising quality expectations.",
      "",
      "### Conceptual Framework",
      "This post uses football icons as metaphors to explore core software testing qualities. By mapping elite player attributes to QA behaviors, we can better understand what makes testing teams truly world-class.",
      "",
      "### Thesis Statement",
      "We’ll explore how Lionel Messi’s dynamism, Neymar Jr’s calmness, and Cristiano Ronaldo’s persistence translate directly into strengths across the QA lifecycle.",
      "",
      "## Messi’s Dynamicity and Adaptability in QA",
      "Messi is renowned for his fluid movement, rapid decision-making, and ability to change direction in an instant. He adapts to defenders, tactics, and match situations seamlessly.",
      "",
      "### Conceptual Link to QA",
      "In software testing, requirements shift, architectures evolve, and priorities change mid-sprint. A “Messi-like” QA engineer:",
      "",
      "- Adapts test strategies quickly when scope changes",
      "- Refactors test cases as systems evolve",
      "- Explores the product creatively, not just by the script",
      "",
      "Dynamic QA professionals excel in exploratory testing, risk-based testing, and early feedback loops—always moving with the product rather than resisting change.",
      "",
      "## Neymar’s Calmness and Steadiness Under Pressure in Testing",
      "Neymar often performs in high-pressure moments—crowded defenses, hostile crowds, and critical match situations—yet maintains composure and flair.",
      "",
      "### Conceptual Link to QA",
      "In QA, pressure peaks during release crunches, production incidents, and last-minute bug discoveries. Calmness becomes a competitive advantage. A “Neymar-like” tester:",
      "",
      "- Stays analytical during incidents instead of reactive",
      "- Communicates clearly with developers and stakeholders",
      "- Makes sound quality decisions even under tight deadlines",
      "",
      "This steadiness ensures that quality does not collapse when speed and stress increase.",
      "",
      "## Ronaldo’s Persistence and Consistency in QA Excellence",
      "Ronaldo’s career is defined by relentless discipline, repetition, and an obsession with improvement. His consistency across seasons and teams is unmatched.",
      "",
      "### Conceptual Link to QA",
      "Quality is not a one-off achievement—it’s sustained effort. A “Ronaldo-like” QA mindset shows up as:",
      "",
      "- Persistent regression testing across releases",
      "- Continuous improvement of automation frameworks",
      "- Long-term ownership of quality metrics and outcomes",
      "",
      "This persistence builds trust in the test suite, the team, and the product over time.",
      "",
      "## Conclusion",
      "### Summary",
      "Messi teaches us adaptability, Neymar reminds us of calm precision, and Ronaldo embodies persistence. Together, these traits form the blueprint of a high-performing QA engineer—one who can adapt to change, stay composed under pressure, and relentlessly pursue quality.",
      "",
      "### Call to Action",
      "Reflect on your own QA practice:",
      "",
      "- Where can you be more dynamic?",
      "- How can you remain calmer under pressure?",
      "- What habits can you build for long-term quality excellence?",
      "",
      "By fostering these qualities individually and within teams, we can build a true culture of excellence—on the pitch and in production."
    ],
    image: '/images/ronaldo-merci-nayma.webp',
    model: '/images/football.glb',
    authorName: 'Sandile Mnqayi',
    authorImage: '/images/SandileMnqayi.jpeg'
  },
];