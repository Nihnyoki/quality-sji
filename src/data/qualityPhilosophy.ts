export interface BlogPost {
  image: string; // thumbnail image path
  model?: string; // optional GLB model path for 3D
  position?: [number, number, number]; // optional [x, y, z] position for 3D scene
  rotationDeg?: [number, number, number]; // optional [x, y, z] rotation in degrees for 3D scene
  authorName?: string;
  authorImage?: string;
  id: string;
  title: string;
  subtitle?: string;
  published: string;
  content: string[];
}

export const qualityPhilosophyPosts: BlogPost[] = [
  {
    id: "dynamic-test-data",
    title: "A Dynamic Test Data Approach",
    subtitle: "Keep intent stable, vary reality meaningfully",
    published: "2026-01-08",
    content: [
      "## Context",
      "Test automation is a powerful tool for enabling fast feedback — I love that about it.",
      "However, many teams struggle to get full value out of automation because their tests run with overly static inputs.",
      "",
      "## The problem with purely static data",
      "Most automated tests validate a specific intent (a function or feature) and therefore need some controlled inputs.",
      "The mistake is treating every input as equally static, even when some values could safely vary without changing the intent being validated.",
      "## A dynamic test data approach",
      "Constraint the critical inputs to a valid range, and use a critiria based input selection method for the tests input parameters. This approach enables the non-critical inputs to vary dynamically.",
      "This can be achieved by implementing a helper function that retrieves a valid test input record from a predefined dataset (for example, a database repository). One very good idea is to use production-aligned data that has been sanitized/anonymized for testing purposes. Additionally, AI suggested (telemetry informed) test scenarios should be implemented to archive a complete end-to-end test automation quality system. Morking and stubbing can be used for non-critical external dependencies, However, mocking is not the ideal approach for the highest quality of signal-to-noise ratio. Additionally, realistic mocking data should be sources from the thrird party system's production data repository, where possible.",
      "",
      "Considering the valid criteria/range based input selection, each retrieved input data set must:",
      "* Satisfy the critical validity criteria required for the test",
      "* Differ only in non-critical attributes",
      "",
      "This ensures that the intent of the test remains stable, while execution conditions vary in a controlled and meaningful way.",
      "",
      "By doing this, you can:",
      "* Increase coverage",
      "* Explore edge cases naturally",
      "* Surface defects that static data would never expose",
      "",
      "All without compromising the intent of the test.",
      "## A Practical Example: Login",
      "To validate authentication, the following inputs must be correct and controlled:",
      "* Username",
      "* Password",
      "These are provided by the helper function, ensuring the test always operates on a valid, authenticated user.",
      "However, the following inputs can vary without invalidating the intent of the test:",
      "* Browser type",
      "* Screen resolution",
      "* Active service subscriptions",
      "* Language settings",
      "One key point: The QA team must be properly equipped and effective in analysing and diagnosing the root cause of the issue when tests fail. This is critical to continuously refine the dataset repository, and to avoid raising invalid defects, thereby increasing the signal-to-noise ratio which reduces confidence in the test suite. This is anyhow important for all test automation. QA Engineers can learn more about tools and methods to optimise signal-to-noise ratio in my [know your tools](/know-your-tools) video series.",
      "This Dynamic Test Data Approach becomes significantly more powerful when test scenarios are informed by [real user AI-assisted telemetry](/quality/telemetry-tests-release-quality-cycle), rather than a limited range of static assumptions.",
      "## Example - Dynamic User Selection",
      "In the example below, the user selected for the test is not static. Instead, it varies over time, while remaining constrained to a defined validity range.",
      "A helper function (getUser) selects a user that meets the specified criteria. While the specific user may change between test executions, the business validity of the scenario is preserved.",
      "",
      "This controlled fluctuation of test users:",
      "* Extends coverage over time",
      "* Exposes behavioral and data-related edge cases",
      "* Increases the likelihood of detecting unforeseen defects",
      "## Cucumber Feature Example",
      "```gherkin",
      "Scenario: User signs into the service under test",
      "  Given a valid user exists in the users repository:",
      "    | Status        | Active |",
      "    | person_minAge | 20     |",
      "    | person_maxAge | 60     |",
      "```",
      "## Cucumber Step Definition Example",
      "```java",
      "//The called service retrieves a user matching the criteria from the users repository.",
      "@Given(\"a valid user exists in the users repository:\")",
      "public void aValidUserExistsInTheUsersRepository(DataTable dt) throws JsonProcessingException {",
      "    Response res = given()",
      "            .formParams(ops.getFormParams(dt))",
      "            .accept(\"application/json\")",
      "            .get();",
      "",
      "    ops.setPerson(res.getBody().as(Person.class));",
      "}",
      "```",
      "In this model:",
      "* The test validates login intent, not a specific individual",
      "* Users are realistic, production-aligned, and diverse",
      "* Coverage grows organically as data varies across executions",
      "## Closing Thought",
      "Dynamic data doesn’t mean unreliable tests.",
      "It means stable intent with realistic variation — and stronger confidence over time. This approach can be paired with the [AI Powered - Telemetry Informed Test Approach](/quality/telemetry-tests-release-quality-cycle) to create a living quality system that adapts to real user behaviour.",
      "This kind of adaptability mirrors the 'Messi-like' quality we explore when mapping elite football traits to [effective QA practices](/quality/pitch-to-product-football-qa).",
    ],
    image: '/images/splashing-water.jpeg',
    model: '/images/dynamic_quality_system.glb',
    authorName: 'Sandile Mnqayi',
    authorImage: '/images/SandileMnqayi.jpeg'
  },
  {
    id: "deadlines-enemy-of-quality",
    title: "When Deadlines Become the Enemy of Quality",
    subtitle: "How deadline-driven incentives quietly train teams to ship risk",
    rotationDeg: [120, 10, 125],
    published: "2026-01-10",
    content: [
      "In many organisations, delivery success is measured by one dominant signal: did we hit the deadline?",
      "Deadlines are usually tied to KPIs, performance reviews, bonuses, and leadership visibility.",
      "On paper, this makes sense — timelines bring structure and predictability.",
      "In practice, however, this incentive model often produces the opposite of what teams intend: lower quality outcomes.",
      "",
      "When meeting a deadline becomes the primary goal, quality quietly becomes optional.",
      "",
      "## The KPI Trap: Speed Over Substance",
      "KPIs are powerful because they shape behaviour.",
      "When teams are rewarded for how fast something is delivered, they naturally optimise for speed.",
      "This leads to:",
      "",
      "- Cutting corners in design and implementation",
      "- Reduced testing depth",
      "- Shortened feedback cycles",
      "- Increased reliance on assumptions rather than evidence",
      "",
      "The problem is not that teams are careless.",
      "The problem is that they are responding rationally to the incentives placed in front of them.",
      "",
      "If quality is not explicitly measured, protected, and rewarded, it will always lose to time pressure.",
      "",
      "## “Just Make the Deadline” Culture",
      "As deadlines approach, pressure tends to cascade downward:",
      "",
      "- Senior leadership pushes product owners",
      "- Product owners push delivery teams",
      "- Delivery teams push QA",
      "",
      "At this stage, conversations shift from “Is this ready?” to “Can we sign this off?”",
      "Quality assurance becomes a gate that must be bypassed rather than a signal to be respected.",
      "",
      "This is where the most damaging behaviour emerges:",
      "QA teams are pressured to approve releases they are not confident in.",
      "",
      "## The Erosion of QA Authority",
      "When deadlines dominate decision-making:",
      "",
      "- QA findings are reframed as “non-blockers”",
      "- Known risks are deferred to “post-release”",
      "- Test coverage is treated as negotiable",
      "- Sign-off becomes ceremonial rather than meaningful",
      "",
      "Over time, this erodes trust in QA as a discipline.",
      "QA stops being a partner in risk management and becomes a formality in the delivery checklist.",
      "",
      "Ironically, the same stakeholders who push for rushed sign-off are often the first to question quality when defects surface in production.",
      "",
      "## The Hidden Cost of Rushed Delivery",
      "What deadline-driven KPIs fail to account for is cost displacement.",
      "",
      "Quality issues do not disappear when they are ignored — they simply move downstream:",
      "",
      "- Production defects",
      "- Customer dissatisfaction",
      "- Emergency hotfixes",
      "- Reputational damage",
      "- Burnout within engineering and QA teams",
      "",
      "The time “saved” before release is often paid back with interest after release.",
      "",
      "## Quality Needs an Incentive Too",
      "The core issue is not deadlines. Deadlines are necessary.",
      "The issue is unbalanced incentives.",
      "",
      "If teams are measured only on when something is delivered, but not on how well it performs, then quality becomes a risk the system is willing to take.",
      "",
      "Healthy delivery organisations balance:",
      "",
      "- Time",
      "- Scope",
      "- Risk",
      "- Quality",
      "",
      "And they give QA the authority to say “not yet” without fear of escalation or blame.",
      "",
      "## A Better Question to Ask",
      "Instead of asking:",
      "",
      "“Can we still make the deadline?”",
      "",
      "Teams should be encouraged to ask:",
      "",
      "“What level of quality are we willing to accept — and are we aligned on that risk?”",
      "",
      "That single shift reframes QA from an obstacle into a strategic partner.",
      "",
      "## Closing Thoughts",
      "When KPIs reward speed alone, they silently train teams to sacrifice quality.",
      "When QA is pressured to sign off against their judgement, quality becomes performative rather than real.",
      "",
      "True delivery maturity is not about hitting every deadline.",
      "It is about delivering outcomes that teams can confidently stand behind — even when that means pushing back.",
      "",
      "Quality does not happen by accident.",
      "It happens when organisations choose to incentivise it."
    ],
    image: '/images/deadlines.webp',
    model: '/images/flag-finish-model.glb',
    authorName: 'Sandile Mnqayi',
    authorImage: '/images/SandileMnqayi.jpeg'
  },
  {
    id: "telemetry-tests-release-quality-cycle",
    title: "Spreading Right - Telemetry to Tests to Release: A User-Behaviour-Driven Quality Cycle",
    rotationDeg: [90, 90, 130],
    published: "2026-01-10",
    content: [
      "One of the biggest gaps in modern software delivery is that testing is often disconnected from reality. Test scenarios are designed based on assumptions, specifications, and edge cases imagined during development, while production quietly tells a different story.",
      "",
      "The question is not how much we test, but how relevant our tests are to real user behaviour.",
      "",
      "By combining telemetry, AI, and test automation, teams can create a closed quality loop where production reality continuously informs what gets tested next.",
      "",
      "## The Core Cycle",
      "The cycle looks like this:",
      "",
      "- Telemetry captures real user behaviour",
      "- AI analyses telemetry and detects patterns",
      "- AI derives test scenarios and realistic input data",
      "- Test automation executes optimized tests in the test environment",
      "- A new release is shaped by these informed tests",
      "- The released system generates new telemetry",
      "- The cycle repeats, continuously improving coverage in key areas.",
      "",
      "The key shift is this:",
      "Test automation runs in the testbed, but learning happens in production.",
      "",
      "## 1. Telemetry as the partner Source of Truth",
      "Production telemetry represents how users actually interact with the system:",
      "",
      "- Navigation paths",
      "- Feature usage frequency",
      "- Real input values",
      "- Error patterns",
      "- Performance bottlenecks",
      "- Drop-offs and retries",
      "",
      "This data exposes the gap between:",
      "",
      "- What we thought users would do",
      "- What they actually do",
      "",
      "Telemetry is not feedback on tests — it is feedback on the product itself. This is BDD personified.",
      "",
      "## 2. AI Interprets Behaviour, Not Intent",
      "Raw telemetry is noisy and overwhelming. AI’s role is to interpret behaviour at scale.",
      "",
      "AI analyses telemetry to:",
      "",
      "- Identify dominant and rare user flows",
      "- Detect anomalies and emerging risk patterns",
      "- Correlate failures with inputs and paths",
      "- Highlight areas with high usage but low test coverage",
      "",
      "Instead of guessing what matters, teams get an evidence-based view of where risk actually lives.",
      "",
      "## 3. AI Derives Test Scenarios and Input Data",
      "This is the most important shift in the model.",
      "",
      "From analysed telemetry, AI can:",
      "",
      "- Identify gaps in the test suite and",
      "- Propose new test scenarios based on real flows",
      "- Generate realistic input data seen in production",
      "- Elevate rare but high-impact edge cases",
      "- De-prioritise low-value, synthetic tests. (An under-estimated cost is the time waisted fixing non-realistic edge cases.)",
      "",
      "Regression tests are no longer speculative, with telemetry informed AI powered test scenarios, they are user-behaviour-driven.",
      "",
      "This results in:",
      "",
      "- Fewer tests",
      "- Higher relevance",
      "",
      "This model pairs naturally with [dynamic test data strategies](/quality/dynamic-test-data-strategies) that preserve intent while allowing realistic variation.",
      "## 4. Test Automation Runs in the Testbed",
      "Execution still happens in controlled test environments, not production.",
      "Telemetry and AI influence what you test next, but tests run safely before release.",
      "",
      "Quality stops being a static checklist and becomes adaptive.",
      "",
      "## Why This Model Matters",
      "This approach solves several systemic problems:",
      "",
      "- Tests stay aligned with real users",
      "- QA is no longer the last-minute gatekeeper",
      "- Risk is identified early, not at deadlines",
      "- Acurate preventative test inteventions are implemented",
      "- Coverage grows where it matters, not where it is easiest",
      "This approach directly counters [deadline-driven quality failures](/quality/deadlines-enemy-of-quality) by surfacing risk early, not at sign-off.",
      "",
      "Most importantly, it shifts the conversation from:",
      "",
      "“Did we test enough?”",
      "",
      "to:",
      "",
      "“Did we test what real users will actually do next?”",
      "",
      "## Closing Thought",
      "Telemetry tells us how the product is used.",
      "AI tells us where risk and opportunity exist.",
      "Test automation ensures those insights are enforced before release.",
      "The release itself becomes the experiment — and telemetry delivers the verdict.",
      "That verdict should then become a key input when prioritizing fixes for the next release cycle, tightening the [incentive model for quality](/quality/deadlines-enemy-of-quality).",
      "This is not faster testing.",
      "Thit is quality engineering driven by reality."
    ],
    image: '/images/telemetry-signals.jpeg',
    model: '/images/binocurlars.glb',
    authorName: 'Sandile Mnqayi',
    authorImage: '/images/SandileMnqayi.jpeg'
  },
  {
    id: "pitch-to-product-football-qa",
    title: "From Pitch to Product: Mapping Football Greats' Strengths to Software Testing Quality",
    published: "2026-01-10",
    content: [
      "## Introduction",
      "",
      "### Hook",
      "Football and software testing might seem worlds apart, but both thrive on discipline, adaptability, and excellence under pressure. Just as legendary footballers read the game, adjust their play, and relentlessly pursue victory, great QA engineers navigate complex systems, shifting requirements, and ever-rising quality expectations.",
      "",
      "### Conceptual Framework",
      "This post uses football icons as metaphors to explore core software testing qualities. By mapping elite player attributes to QA behaviors, we can better understand what makes testing teams truly world-class.",
      "",
      "### Thesis Statement",
      "We’ll explore how Lionel Messi’s dynamism, Neymar Jr’s calmness, and Cristiano Ronaldo’s persistence translate directly into strengths across the QA lifecycle.",
      "",
      "## Messi’s Dynamicity and Adaptability in QA",
      "Messi is renowned for his fluid movement, rapid decision-making, and ability to change direction in an instant. He adapts to defenders, tactics, and match situations seamlessly.",
      "This adaptability shows up practically in approaches like [dynamic test data](/quality/dynamic-test-data-strategies), where intent remains stable but reality is allowed to vary.",
      "",

      "### Conceptual Link to QA",
      "In software testing, requirements shift, architectures evolve, and priorities change mid-sprint. A “Messi-like” QA engineer:",
      "",
      "- Adapts test strategies quickly when scope changes - laveraging AI for quick test case and test scripts generation.",
      "- Refactors test cases as systems evolve - it is important to branch the working tree to maintain rediness for backwards compatibility testing.",
      "- Explores the product creatively, not just by the script - a good QA engineer must know the product requirements well, and the product roadmap. This enables them not to simply test the current feature correctly, but also to explore related areas that might be impacted (lagacy features and planned work). Context is king.",
      "",
      "Dynamic QA professionals excel in exploratory testing, risk-based testing, and early feedback loops—always moving with the product rather than resisting change.",
      "",
      "## Neymar’s Calmness and Steadiness Under Pressure in Testing",
      "Neymar often performs in high-pressure moments—crowded defenses, hostile crowds, and critical match situations—yet maintains composure and flair.",
      "[Deadline-driven cultures](/quality/deadlines-enemy-of-quality) often remove this calm, replacing judgement with urgency.",
      "",
      "### Conceptual Link to QA",
      "In QA, pressure peaks during release crunches, production incidents, and last-minute bug discoveries. Calmness becomes a competitive advantage. A “Neymar-like” tester:",
      "",
      "- Stays analytical during incidents instead of reactive - focusing on root cause rather than symptoms.",
      "- Communicates clearly with developers and stakeholders - providing clear and revelent data (account-details, logs, payloads, screenshots, context...) to help with root cause analysis.",
      "- Makes sound quality decisions even under tight deadlines - prioritising high-risk areas for testing rather than trying to test everything superficially.",
      "",
      "This steadiness ensures that quality does not collapse when speed and stress increase.",
      "",
      "## Ronaldo’s Persistence and Consistency in QA Excellence",
      "Ronaldo’s career is defined by relentless discipline, repetition, and an obsession with improvement. His consistency across seasons and teams is unmatched.",
      "Persistent quality at scale is only achievable through continuous feedback systems like [telemetry-informed testing cycles](/quality/telemetry-informed-testing-cycles).",
      "",
      "### Conceptual Link to QA",
      "Quality is not a one-off achievement—it’s sustained effort. A “Ronaldo-like” QA mindset shows up as:",
      "",
      "- Persistent regression testing across releases - and reporting a timeline trend of feature/release perfomance.",
      "- Continuous improvement of automation frameworks - this means preparing automation scripts that support multiple environments and integrate with CI/CD pipelines.",
      "- Long-term ownership of quality metrics and outcomes - tracking defect trends, test coverage, and user feedback.",
      "",
      "This persistence builds trust in the test suite, the team, and the product over time.",
      "",
      "## Conclusion",
      "### Summary",
      "Messi teaches us adaptability, Neymar reminds us of calm precision, and Ronaldo embodies persistence. Together, these traits form the blueprint of a high-performing QA engineer—one who can adapt to change, stay composed under pressure, and relentlessly pursue quality.",
      "",
      "### Call to Action",
      "Reflect on your own QA practice:",
      "",
      "- Where can you be more dynamic?",
      "- How can you remain calmer under pressure?",
      "- What habits can you build for long-term quality excellence?",
      "",
      "By fostering these qualities individually and within teams, we can build a true culture of excellence—on the pitch and in production."
    ],
    image: '/images/ronaldo-merci-nayma.webp',
    model: '/images/football.glb',
    authorName: 'Sandile Mnqayi',
    authorImage: '/images/SandileMnqayi.jpeg'
  },
];